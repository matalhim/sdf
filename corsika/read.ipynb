{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from corsikaio import CorsikaFile\n",
    "import re\n",
    "import struct\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'pDAT163010'\n",
    "metadata_filename = f'{filename}.dbase'\n",
    "file_path = f'data/p30/{filename}' \n",
    "metadata_file_path = f'data/p30/{metadata_filename}' \n",
    "\n",
    "save_path = f'csv_otput/{filename}_output' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(save_path, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metadata(file_path):\n",
    "    metadata = {}\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip() \n",
    "\n",
    "            match = re.search(r'#howmanyshowers#\\s*(\\d+)', line)\n",
    "            if match:\n",
    "                metadata['howmanyshowers'] = int(match.group(1))\n",
    "\n",
    "            match = re.search(r'#energy_prim#\\s*([\\d\\.eE\\+\\-]+)', line)\n",
    "            if match:\n",
    "                metadata['energy_prim'] = float(match.group(1))\n",
    "\n",
    "            match = re.search(r'#theta_prim#\\s*([\\d\\.eE\\+\\-]+)', line)\n",
    "            if match:\n",
    "                metadata['theta_prim'] = float(match.group(1))\n",
    "\n",
    "            match = re.search(r'#phi_prim#\\s*([\\d\\.eE\\+\\-]+)', line)\n",
    "            if match:\n",
    "                metadata['phi_prim'] = float(match.group(1))\n",
    "\n",
    "            match = re.search(r'#dsn_events#\\s*(\\S+)', line)\n",
    "            if match:\n",
    "                metadata['dsn_events'] = match.group(1)\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PID_MAP = {\n",
    "    1: \"gamma\", 2: \"e-\", 3: \"e+\", 4: \"ν_e\", 5: \"μ-\", 6: \"μ+\",\n",
    "    7: \"π⁰\", 8: \"π+\", 9: \"π-\", 13: \"n\", 14: \"p\", 75: \"Fe\",\n",
    "    25: \"Λ⁰\", 35: \"Σ⁺\", 45: \"Ξ⁰\", 55: \"Ω⁻\", 65: \"anti-proton\",\n",
    "}\n",
    "\n",
    "def pid_name(pid_raw):\n",
    "    \"\"\"Преобразует 'сырой' PID в читаемое имя\"\"\"\n",
    "    base_pid = pid_raw // 1000\n",
    "    return PID_MAP.get(base_pid, f\"unknown({base_pid})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_event_data(event_idx, particles, header, save_path):\n",
    "    theta_prim = header.get('theta_prim', 0)\n",
    "    phi_prim = header.get('phi_prim', 0)\n",
    "    energy_prim = header.get('energy_prim', 0)\n",
    "\n",
    "    \n",
    "    event_data = []\n",
    "\n",
    "    for p in particles:\n",
    "        raw_pid = int(p[0])\n",
    "        base_pid = raw_pid // 1000\n",
    "        name = pid_name(raw_pid)\n",
    "        \n",
    "        px, py, pz = p[1], p[2], p[3]\n",
    "        x, y, t = p[4] / 100, p[5] / 100, p[6]\n",
    "        energy = np.sqrt(px**2 + py**2 + pz**2)\n",
    "        \n",
    "        event_data.append({\n",
    "            'event_id': event_idx,\n",
    "            'particle_name': name,\n",
    "            'pid': base_pid,\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            't': t,\n",
    "            'energy': energy,\n",
    "            'theta_prim': theta_prim,\n",
    "            'phi_prim': phi_prim,\n",
    "            'energy_prim': energy_prim,\n",
    "        })\n",
    "    \n",
    "    df_event = pd.DataFrame(event_data)\n",
    "    event_file = os.path.join(save_path, f\"event_{event_idx}.csv\")\n",
    "    df_event.to_csv(event_file, index=False)\n",
    "    print(f\"Сохранены данные события {event_idx} в файл: {event_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохранены данные события 0 в файл: csv_otput/pDAT163010_output\\event_0.csv\n",
      "Сохранены данные события 1 в файл: csv_otput/pDAT163010_output\\event_1.csv\n",
      "Сохранены данные события 2 в файл: csv_otput/pDAT163010_output\\event_2.csv\n",
      "Сохранены данные события 3 в файл: csv_otput/pDAT163010_output\\event_3.csv\n",
      "Сохранены данные события 4 в файл: csv_otput/pDAT163010_output\\event_4.csv\n"
     ]
    }
   ],
   "source": [
    "with CorsikaFile(file_path) as f:\n",
    "    for event_idx, event in enumerate(f):\n",
    "        header = event.header\n",
    "        particles = event.data\n",
    "        \n",
    "        metadata = parse_metadata(metadata_file_path) \n",
    "        if isinstance(header, np.void):\n",
    "            header = {field: header[field] for field in header.dtype.names}\n",
    "        \n",
    "        header.update(metadata) \n",
    "        save_event_data(event_idx, particles, header, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ливень 1: NeNKG = 391831.96875, sNKG = 1.3683958053588867\n",
      "Ливень 2: NeNKG = 1135387.0, sNKG = 1.259588599205017\n",
      "Ливень 3: NeNKG = 307665.75, sNKG = 1.3709015846252441\n",
      "Ливень 4: NeNKG = 723334.4375, sNKG = 1.371324896812439\n",
      "Ливень 5: NeNKG = 414350.84375, sNKG = 1.3645058870315552\n",
      "Найден блок RUNE, завершаем обработку.\n"
     ]
    }
   ],
   "source": [
    "params_dict: dict[int, [float]] = {}\n",
    "\n",
    "def parse_corsika_showers(file_path):\n",
    "    \"\"\"\n",
    "    Читает бинарный файл CORSIKA и группирует данные по шалам:\n",
    "      - Заголовок 'EVTH' задаёт начало события.\n",
    "      - Заголовок 'EVTE' содержит параметры NeNKG и sNKG.\n",
    "    При нахождении блока RUNE обработка завершается.\n",
    "    \"\"\"\n",
    "    current_shower = None \n",
    "    shower_count = 0     \n",
    "\n",
    "    with open(file_path, 'rb') as f:\n",
    "        while True:\n",
    "            marker_bytes = f.read(4)\n",
    "            if len(marker_bytes) < 4:\n",
    "                break\n",
    "\n",
    "            record_size = struct.unpack('i', marker_bytes)[0]\n",
    "            if record_size <= 0:\n",
    "                print(\"Некорректный размер записи:\", record_size)\n",
    "                break\n",
    "\n",
    "            block_bytes = f.read(record_size)\n",
    "            if len(block_bytes) != record_size:\n",
    "                print(\"Ошибка чтения: получено\", len(block_bytes), \"байт, ожидалось\", record_size)\n",
    "                break\n",
    "\n",
    "            end_marker = f.read(4)\n",
    "            if len(end_marker) < 4:\n",
    "                print(\"Неверное завершение записи.\")\n",
    "                break\n",
    "\n",
    "            num_floats = record_size // 4\n",
    "            block = np.frombuffer(block_bytes, dtype=np.float32, count=num_floats)\n",
    "\n",
    "            num_subblocks = 21\n",
    "            subblock_size = 273\n",
    "\n",
    "            for j in range(num_subblocks):\n",
    "                start = j * subblock_size\n",
    "                end = start + subblock_size\n",
    "                if end > len(block):\n",
    "                    break\n",
    "\n",
    "                subblock = block[start:end]\n",
    "                header_bytes = subblock[0].tobytes()\n",
    "                try:\n",
    "                    header_str = header_bytes.decode('ascii')\n",
    "                except UnicodeDecodeError:\n",
    "                    header_str = \"\"\n",
    "\n",
    "                if header_str == 'EVTH':\n",
    "                    shower_count += 1\n",
    "                    current_shower = shower_count\n",
    "                    # print(f\"Начало ливня {current_shower} (найден EVTH)\")\n",
    "                elif header_str == 'EVTE':\n",
    "                    if current_shower is not None:\n",
    "                        idx_ne = 175 + 10 - 1\n",
    "                        idx_s  = 185 + 10 - 1  \n",
    "                        if len(subblock) > max(idx_ne, idx_s):\n",
    "                            ne_nkg = subblock[idx_ne]\n",
    "                            s_nkg  = subblock[idx_s]\n",
    "                            print(f\"Ливень {current_shower}: NeNKG = {ne_nkg}, sNKG = {s_nkg}\")\n",
    "                            params_dict[current_shower-1] = [ne_nkg, s_nkg]\n",
    "                            current_shower = None\n",
    "                        else:\n",
    "                            print(f\"Ливень {current_shower}: подблок EVTE слишком короткий\")\n",
    "                elif header_str == 'RUNE':\n",
    "                    print(\"Найден блок RUNE, завершаем обработку.\")\n",
    "                    return\n",
    "\n",
    "file_path = 'data/p30/pDAT163010' \n",
    "parse_corsika_showers(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(params_dict, orient='index', columns=['Ne', 's'])\n",
    "df.index.name = 'ID'\n",
    "df.reset_index(inplace=True)  \n",
    "\n",
    "df.columns = ['event_id', 'Ne', 's']\n",
    "\n",
    "theta, phi, E_prim = [], [], []\n",
    "for i in df['event_id']:\n",
    "    df_event = pd.read_csv(save_path + f'/event_{i}.csv')\n",
    "    theta.append(df_event.iloc[0]['theta_prim'])\n",
    "    phi.append(df_event.iloc[0]['phi_prim'])\n",
    "    E_prim.append(df_event.iloc[0]['energy_prim'])\n",
    "    \n",
    "df['theta'] = theta\n",
    "df['phi'] = phi\n",
    "df['E_prim'] = E_prim\n",
    "  \n",
    "\n",
    "df.to_csv(save_path + '/_params.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
